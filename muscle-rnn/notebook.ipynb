{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muscle Arm RNN Control\n",
    "\n",
    "A biologically-inspired neural network controller for a MuJoCo muscle-driven arm.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "### Neural Network Modules (`models/modules/`)\n",
    "- **SensoryModule**: Biologically-inspired proprioceptive neurons\n",
    "  - Type Ia: Velocity-sensitive (muscle spindle primary)\n",
    "  - Type II: Length-sensitive (muscle spindle secondary)  \n",
    "  - Type Ib: Force-sensitive (Golgi tendon organ)\n",
    "- **TargetEncoder**: Gaussian-tuned spatial grid for target position\n",
    "- **RNNCore / MLPCore**: Main processing module (RNN has recurrent layer)\n",
    "- **MotorModule**: Alpha MNs + Gamma static/dynamic outputs\n",
    "\n",
    "### Controller-Level Features (`models/controllers.py`)\n",
    "- **Monosynaptic Stretch Reflex Arcs**: Type Ia/II → Alpha MN connections\n",
    "  - Implemented at controller level (not in motor module)\n",
    "  - Allows different controllers to have different reflex configurations\n",
    "\n",
    "### Environment (`envs/`)\n",
    "- **plant.py**: MuJoCo physics interface with XML parsing\n",
    "- **reaching.py**: Center-out reaching task with phased trials\n",
    "\n",
    "### Training Methods\n",
    "1. **CMA-ES**: Black-box evolutionary optimization\n",
    "2. **Distillation**: MLP teacher → RNN student knowledge transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path\n",
    "import sys\n",
    "sys.path.insert(0, '.')  # Adjust if notebook is not in project root\n",
    "\n",
    "# Core imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Information\n",
    "\n",
    "Parse the MuJoCo XML to see what's in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.plant import parse_mujoco_xml, get_model_dimensions\n",
    "\n",
    "XML_PATH = 'mujoco/arm.xml'\n",
    "\n",
    "parsed = parse_mujoco_xml(XML_PATH)\n",
    "dims = get_model_dimensions(parsed)\n",
    "\n",
    "print(f\"Model: {parsed.model_name}\")\n",
    "print(f\"Timestep: {parsed.timestep}s\")\n",
    "print(f\"\\nJoints ({parsed.num_joints}):\")\n",
    "for j in parsed.joints:\n",
    "    print(f\"  - {j.name}: {j.joint_type}, range={j.range}\")\n",
    "\n",
    "print(f\"\\nMuscles ({parsed.num_muscles}):\")\n",
    "for m in parsed.muscles:\n",
    "    print(f\"  - {m.name}: force={m.force}N\")\n",
    "\n",
    "print(f\"\\nSensors ({parsed.num_sensors}):\")\n",
    "for s in parsed.sensors:\n",
    "    print(f\"  - {s.name}: {s.sensor_type}\")\n",
    "\n",
    "print(f\"\\nNetwork Dimensions:\")\n",
    "for k, v in dims.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sensor Calibration\n",
    "\n",
    "Run random episodes to gather sensor statistics for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.plant import calibrate_sensors\n",
    "from envs.reaching import ReachingEnv\n",
    "\n",
    "# Run calibration (takes ~30 seconds)\n",
    "print(\"Calibrating sensors...\")\n",
    "sensor_stats = calibrate_sensors(XML_PATH, num_episodes=50, max_steps=200)\n",
    "\n",
    "print(\"\\nSensor Statistics:\")\n",
    "for k, v in sensor_stats.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Save for later use\n",
    "with open('sensor_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(sensor_stats, f)\n",
    "print(\"\\nSaved to sensor_stats.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Environment\n",
    "\n",
    "The environment now provides raw target XYZ position (not encoded).\n",
    "Target encoding is done by the controller's TargetEncoder module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = ReachingEnv(XML_PATH, sensor_stats=sensor_stats)\n",
    "\n",
    "print(f\"Observation space: {env.observation_space.shape}\")\n",
    "print(f\"  - Proprioceptive: {env.num_muscles * 3} (length, velocity, force per muscle)\")\n",
    "print(f\"  - Target: 3 (raw XYZ position)\")\n",
    "print(f\"Action space: {env.action_space.shape}\")\n",
    "print(f\"  - Alpha MN activations only\")\n",
    "\n",
    "# Run a test episode with random actions\n",
    "obs, info = env.reset()\n",
    "print(f\"\\nInitial info: {info}\")\n",
    "\n",
    "total_reward = 0\n",
    "for step in range(200):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    if step % 50 == 0:\n",
    "        print(f\"Step {step}: phase={info['phase']}, distance={info['distance_to_target']:.3f}\")\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "print(f\"\\nEpisode finished after {step+1} steps, total reward: {total_reward:.2f}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Modules\n",
    "\n",
    "Let's look at the individual neural network modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modules import SensoryModule, MotorModule, TargetEncoder, RNNCore\n",
    "\n",
    "num_muscles = parsed.num_muscles\n",
    "num_target_units = 16  # 4x4 grid\n",
    "\n",
    "# Sensory module\n",
    "sensory = SensoryModule(num_muscles=num_muscles, use_bias=True)\n",
    "print(f\"SensoryModule:\")\n",
    "print(f\"  - Type Ia (velocity): {num_muscles} units\")\n",
    "print(f\"  - Type II (length): {num_muscles} units\")\n",
    "print(f\"  - Type Ib (force): {num_muscles} units\")\n",
    "print(f\"  - Output: {num_muscles * 3} total\")\n",
    "\n",
    "# Target encoder (converts XYZ to Gaussian grid)\n",
    "target_encoder = TargetEncoder(grid_size=4, sigma=0.25)\n",
    "print(f\"\\nTargetEncoder:\")\n",
    "print(f\"  - Grid: 4x4 = 16 units\")\n",
    "print(f\"  - Sigma: 0.25\")\n",
    "\n",
    "# Test encoding a target\n",
    "test_target = torch.tensor([[0.1, 0.2, 0.0]])\n",
    "encoded = target_encoder.encode(test_target)\n",
    "print(f\"  - Input: {test_target.shape}\")\n",
    "print(f\"  - Output: {encoded.shape}\")\n",
    "\n",
    "# Motor module (cortical outputs only - reflex is at controller level)\n",
    "motor = MotorModule(input_size=32, num_muscles=num_muscles)\n",
    "print(f\"\\nMotorModule (cortical pathway):\")\n",
    "print(f\"  - Alpha MN: {num_muscles} outputs\")\n",
    "print(f\"  - Gamma static: {num_muscles} outputs\")\n",
    "print(f\"  - Gamma dynamic: {num_muscles} outputs\")\n",
    "print(f\"\\nNote: Reflex arcs (Ia→Alpha, II→Alpha) are at controller level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Controller\n",
    "\n",
    "Initialize the RNN controller and inspect its architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.config import ModelConfig\n",
    "from models.controllers import RNNController, MLPController, create_controller\n",
    "\n",
    "# Create model config\n",
    "config = ModelConfig(\n",
    "    num_muscles=parsed.num_muscles,\n",
    "    num_sensors=parsed.num_sensors,\n",
    "    num_target_units=16,  # 4x4 grid\n",
    "    rnn_hidden_size=32,\n",
    "    rnn_type='rnn',\n",
    "    # Bias settings\n",
    "    proprioceptive_bias=True,\n",
    "    target_encoding_bias=True,\n",
    "    output_bias=True,\n",
    "    reflex_bias=False,  # Reflexes typically don't have bias\n",
    ")\n",
    "\n",
    "print(\"Config:\")\n",
    "print(f\"  num_muscles: {config.num_muscles}\")\n",
    "print(f\"  num_sensors: {config.num_sensors}\")\n",
    "print(f\"  num_target_units: {config.num_target_units}\")\n",
    "print(f\"  rnn_hidden_size: {config.rnn_hidden_size}\")\n",
    "\n",
    "# Create RNN controller\n",
    "rnn_controller = RNNController(config)\n",
    "print(f\"\\nRNN Controller: {rnn_controller.count_parameters():,} parameters\")\n",
    "\n",
    "# Create MLP controller (for comparison)\n",
    "mlp_controller = MLPController(config)\n",
    "print(f\"MLP Controller: {mlp_controller.count_parameters():,} parameters\")\n",
    "\n",
    "# Show reflex weights location\n",
    "print(\"\\nReflex weights (at controller level):\")\n",
    "for name, param in rnn_controller.named_parameters():\n",
    "    if 'to_alpha' in name:\n",
    "        print(f\"  - {name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "batch_size = 1\n",
    "obs_dim = config.num_sensors + 3  # sensors + raw XYZ target\n",
    "dummy_obs = torch.randn(batch_size, obs_dim)\n",
    "\n",
    "rnn_controller.eval()\n",
    "rnn_controller.init_hidden(batch_size, torch.device('cpu'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    action, hidden, info = rnn_controller(dummy_obs)\n",
    "\n",
    "print(f\"Input observation: {dummy_obs.shape}\")\n",
    "print(f\"Output action (alpha MN): {action.shape}\")\n",
    "print(f\"\\nInfo dict keys: {list(info.keys())}\")\n",
    "print(f\"  - alpha: {info['alpha'].shape} (final output)\")\n",
    "print(f\"  - alpha_cortical: {info['alpha_cortical'].shape} (before reflex)\")\n",
    "print(f\"  - gamma_static: {info['gamma_static'].shape}\")\n",
    "print(f\"  - gamma_dynamic: {info['gamma_dynamic'].shape}\")\n",
    "print(f\"  - sensory_outputs: {list(info['sensory_outputs'].keys())}\")\n",
    "print(f\"  - rnn_hidden: {info['rnn_hidden'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Method 1: CMA-ES\n",
    "\n",
    "CMA-ES (Covariance Matrix Adaptation Evolution Strategy) is a black-box optimization method that evolves network weights without computing gradients.\n",
    "\n",
    "**Advantages:**\n",
    "- Works with non-differentiable objectives\n",
    "- Good exploration of parameter space\n",
    "- Parallelizable across CPUs\n",
    "\n",
    "**Note**: Set `use_multiprocessing=False` for Jupyter compatibility, or run from command line for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train_cmaes import run_cmaes_training\n",
    "\n",
    "# CMA-ES Training\n",
    "cmaes_results = run_cmaes_training(\n",
    "    xml_path=XML_PATH,\n",
    "    output_dir='outputs/cmaes',\n",
    "    num_generations=100,        # Increase for better results (500+ recommended)\n",
    "    population_size=32,\n",
    "    sigma_init=0.1,\n",
    "    use_multiprocessing=False,  # Set False for Jupyter\n",
    "    calibration_episodes=30,\n",
    "    save_checkpoint_every=25,\n",
    "    inspection_every=25,        # Generate inspection plots periodically\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CMA-ES Training Complete!\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Best fitness: {cmaes_results['best_fitness']:.2f}\")\n",
    "print(f\"Generations: {cmaes_results['generations']}\")\n",
    "print(f\"Time: {cmaes_results['total_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Method 2: Distillation\n",
    "\n",
    "Distillation training uses a two-phase approach:\n",
    "1. Train an MLP \"teacher\" network using behavioral cloning\n",
    "2. Train an RNN \"student\" to imitate the teacher's behavior\n",
    "\n",
    "**Advantages:**\n",
    "- Leverages gradient-based optimization (faster convergence)\n",
    "- Teacher can use larger capacity\n",
    "- Student RNN learns temporal dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train_distillation import run_distillation_training\n",
    "\n",
    "# Distillation Training\n",
    "distill_results = run_distillation_training(\n",
    "    xml_path=XML_PATH,\n",
    "    output_dir='outputs/distillation',\n",
    "    teacher_epochs=50,          # MLP teacher training\n",
    "    student_epochs=100,         # RNN student training\n",
    "    calibration_episodes=30,\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Distillation Training Complete!\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Teacher success rate: {distill_results.get('teacher_success_rate', 0):.1%}\")\n",
    "print(f\"Student success rate: {distill_results.get('student_success_rate', 0):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load and Compare Both Controllers\n",
    "\n",
    "Load both trained controllers and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization import load_controller, evaluate_controller\n",
    "\n",
    "# Paths to trained controllers\n",
    "CMAES_PATH = 'outputs/cmaes/best_controller_final.pt'\n",
    "DISTILL_PATH = 'outputs/distillation/student_rnn.pt'\n",
    "\n",
    "# Load CMA-ES controller\n",
    "cmaes_controller, cmaes_config, cmaes_ckpt = load_controller(CMAES_PATH)\n",
    "cmaes_controller.eval()\n",
    "print(f\"CMA-ES Controller: {cmaes_controller.count_parameters():,} params\")\n",
    "print(f\"  Fitness: {cmaes_ckpt.get('fitness', 'N/A')}\")\n",
    "print(f\"  Generation: {cmaes_ckpt.get('generation', 'N/A')}\")\n",
    "\n",
    "# Load Distillation controller\n",
    "distill_controller, distill_config, distill_ckpt = load_controller(DISTILL_PATH)\n",
    "distill_controller.eval()\n",
    "print(f\"\\nDistillation Controller: {distill_controller.count_parameters():,} params\")\n",
    "\n",
    "# Load sensor stats (same for both)\n",
    "sensor_stats_path = Path(CMAES_PATH).parent / 'sensor_stats.pkl'\n",
    "with open(sensor_stats_path, 'rb') as f:\n",
    "    sensor_stats = pickle.load(f)\n",
    "print(f\"\\nLoaded sensor stats from {sensor_stats_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quantitative Comparison\n",
    "\n",
    "Evaluate both controllers on the same set of episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization import compare_controllers\n",
    "\n",
    "# Side-by-side comparison\n",
    "comparison = compare_controllers(\n",
    "    controller_paths=[CMAES_PATH, DISTILL_PATH],\n",
    "    labels=['CMA-ES', 'Distillation'],\n",
    "    xml_path=XML_PATH,\n",
    "    sensor_stats=sensor_stats,\n",
    "    num_episodes=50\n",
    ")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<25} {'CMA-ES':>15} {'Distillation':>15}\")\n",
    "print(\"-\"*60)\n",
    "for label in ['CMA-ES', 'Distillation']:\n",
    "    r = comparison[label]\n",
    "    if label == 'CMA-ES':\n",
    "        print(f\"{'Success Rate':<25} {r['success_rate']:>14.1%} \", end='')\n",
    "    else:\n",
    "        print(f\"{r['success_rate']:>14.1%}\")\n",
    "        \n",
    "print(f\"{'Mean Reward':<25} {comparison['CMA-ES']['mean_reward']:>15.2f} {comparison['Distillation']['mean_reward']:>15.2f}\")\n",
    "print(f\"{'Std Reward':<25} {comparison['CMA-ES']['std_reward']:>15.2f} {comparison['Distillation']['std_reward']:>15.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization import plot_reflex_connections\n",
    "\n",
    "# Compare reflex connections between the two controllers\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# CMA-ES reflex weights\n",
    "for name, param in cmaes_controller.named_parameters():\n",
    "    if 'Ia_to_alpha' in name and 'weight' in name:\n",
    "        im = axes[0, 0].imshow(param.data.cpu().numpy(), cmap='RdBu_r', aspect='auto')\n",
    "        axes[0, 0].set_title('CMA-ES: Ia → Alpha')\n",
    "        plt.colorbar(im, ax=axes[0, 0])\n",
    "    elif 'II_to_alpha' in name and 'weight' in name:\n",
    "        im = axes[0, 1].imshow(param.data.cpu().numpy(), cmap='RdBu_r', aspect='auto')\n",
    "        axes[0, 1].set_title('CMA-ES: II → Alpha')\n",
    "        plt.colorbar(im, ax=axes[0, 1])\n",
    "\n",
    "# Distillation reflex weights\n",
    "for name, param in distill_controller.named_parameters():\n",
    "    if 'Ia_to_alpha' in name and 'weight' in name:\n",
    "        im = axes[1, 0].imshow(param.data.cpu().numpy(), cmap='RdBu_r', aspect='auto')\n",
    "        axes[1, 0].set_title('Distillation: Ia → Alpha')\n",
    "        plt.colorbar(im, ax=axes[1, 0])\n",
    "    elif 'II_to_alpha' in name and 'weight' in name:\n",
    "        im = axes[1, 1].imshow(param.data.cpu().numpy(), cmap='RdBu_r', aspect='auto')\n",
    "        axes[1, 1].set_title('Distillation: II → Alpha')\n",
    "        plt.colorbar(im, ax=axes[1, 1])\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('Sensory Neuron (muscle)')\n",
    "    ax.set_ylabel('Alpha MN (muscle)')\n",
    "\n",
    "plt.suptitle('Stretch Reflex Connections Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Episode Recording and Analysis\n",
    "\n",
    "Record episodes from both controllers and compare their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization import record_episode\n",
    "\n",
    "# Record episodes with same seed for fair comparison\n",
    "SEED = 42\n",
    "\n",
    "# CMA-ES episode\n",
    "cmaes_trajectory = record_episode(\n",
    "    controller=cmaes_controller,\n",
    "    xml_path=XML_PATH,\n",
    "    sensor_stats=sensor_stats,\n",
    "    max_steps=300,\n",
    "    seed=SEED,\n",
    ")\n",
    "cmaes_reward = sum(cmaes_trajectory['rewards'])\n",
    "print(f\"CMA-ES Episode: {len(cmaes_trajectory['rewards'])} steps, reward={cmaes_reward:.2f}\")\n",
    "\n",
    "# Distillation episode\n",
    "distill_trajectory = record_episode(\n",
    "    controller=distill_controller,\n",
    "    xml_path=XML_PATH,\n",
    "    sensor_stats=sensor_stats,\n",
    "    max_steps=300,\n",
    "    seed=SEED,\n",
    ")\n",
    "distill_reward = sum(distill_trajectory['rewards'])\n",
    "print(f\"Distillation Episode: {len(distill_trajectory['rewards'])} steps, reward={distill_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization import plot_episode_summary\n",
    "\n",
    "# Side-by-side episode summaries\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# CMA-ES summary\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('CMA-ES Controller', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot motor outputs comparison\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 12), sharex=True)\n",
    "\n",
    "# CMA-ES motor outputs\n",
    "for i in range(cmaes_trajectory['alpha'].shape[1]):\n",
    "    axes[0, 0].plot(cmaes_trajectory['alpha'][:, i], label=f'M{i+1}')\n",
    "axes[0, 0].set_ylabel('Alpha MN')\n",
    "axes[0, 0].set_title('CMA-ES Controller')\n",
    "axes[0, 0].legend(loc='upper right')\n",
    "\n",
    "for i in range(cmaes_trajectory['gamma_static'].shape[1]):\n",
    "    axes[1, 0].plot(cmaes_trajectory['gamma_static'][:, i])\n",
    "axes[1, 0].set_ylabel('Gamma Static')\n",
    "\n",
    "for i in range(cmaes_trajectory['gamma_dynamic'].shape[1]):\n",
    "    axes[2, 0].plot(cmaes_trajectory['gamma_dynamic'][:, i])\n",
    "axes[2, 0].set_ylabel('Gamma Dynamic')\n",
    "axes[2, 0].set_xlabel('Step')\n",
    "\n",
    "# Distillation motor outputs\n",
    "for i in range(distill_trajectory['alpha'].shape[1]):\n",
    "    axes[0, 1].plot(distill_trajectory['alpha'][:, i], label=f'M{i+1}')\n",
    "axes[0, 1].set_title('Distillation Controller')\n",
    "axes[0, 1].legend(loc='upper right')\n",
    "\n",
    "for i in range(distill_trajectory['gamma_static'].shape[1]):\n",
    "    axes[1, 1].plot(distill_trajectory['gamma_static'][:, i])\n",
    "\n",
    "for i in range(distill_trajectory['gamma_dynamic'].shape[1]):\n",
    "    axes[2, 1].plot(distill_trajectory['gamma_dynamic'][:, i])\n",
    "axes[2, 1].set_xlabel('Step')\n",
    "\n",
    "plt.suptitle('Motor Output Comparison (Same Target)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sensory processing\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 10), sharex=True)\n",
    "\n",
    "# CMA-ES sensory\n",
    "axes[0, 0].plot(cmaes_trajectory['sensory_Ia'])\n",
    "axes[0, 0].set_ylabel('Type Ia\\n(velocity)')\n",
    "axes[0, 0].set_title('CMA-ES Sensory Activity')\n",
    "\n",
    "axes[1, 0].plot(cmaes_trajectory['sensory_II'])\n",
    "axes[1, 0].set_ylabel('Type II\\n(length)')\n",
    "\n",
    "axes[2, 0].plot(cmaes_trajectory['sensory_Ib'])\n",
    "axes[2, 0].set_ylabel('Type Ib\\n(force)')\n",
    "axes[2, 0].set_xlabel('Step')\n",
    "\n",
    "# Distillation sensory\n",
    "axes[0, 1].plot(distill_trajectory['sensory_Ia'])\n",
    "axes[0, 1].set_title('Distillation Sensory Activity')\n",
    "\n",
    "axes[1, 1].plot(distill_trajectory['sensory_II'])\n",
    "\n",
    "axes[2, 1].plot(distill_trajectory['sensory_Ib'])\n",
    "axes[2, 1].set_xlabel('Step')\n",
    "\n",
    "plt.suptitle('Proprioceptive Sensory Neuron Activity', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Network Activity Visualization\n",
    "\n",
    "Visualize the neural network as a spatial diagram with colored units representing activation levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.episode_recorder import record_and_save\n",
    "\n",
    "# Record CMA-ES with full network visualization\n",
    "print(\"Recording CMA-ES episode with network visualization...\")\n",
    "cmaes_data = record_and_save(\n",
    "    controller=cmaes_controller,\n",
    "    xml_path=XML_PATH,\n",
    "    sensor_stats=sensor_stats,\n",
    "    output_dir='outputs/cmaes/visualizations',\n",
    "    max_steps=300,\n",
    "    seed=42,\n",
    "    fps=30,\n",
    ")\n",
    "print(f\"  Episode length: {len(cmaes_data.rewards)} steps\")\n",
    "print(f\"  Total reward: {sum(cmaes_data.rewards):.2f}\")\n",
    "print(f\"  Saved to: outputs/cmaes/visualizations/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record Distillation with full network visualization\n",
    "print(\"Recording Distillation episode with network visualization...\")\n",
    "distill_data = record_and_save(\n",
    "    controller=distill_controller,\n",
    "    xml_path=XML_PATH,\n",
    "    sensor_stats=sensor_stats,\n",
    "    output_dir='outputs/distillation/visualizations',\n",
    "    max_steps=300,\n",
    "    seed=42,\n",
    "    fps=30,\n",
    ")\n",
    "print(f\"  Episode length: {len(distill_data.rewards)} steps\")\n",
    "print(f\"  Total reward: {sum(distill_data.rewards):.2f}\")\n",
    "print(f\"  Saved to: outputs/distillation/visualizations/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Display Network Activity Frames\n",
    "\n",
    "Show single frames from the network visualization to see the spatial layout of neural activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display frames at different phases\n",
    "from PIL import Image\n",
    "\n",
    "def show_frame(data, step, title):\n",
    "    \"\"\"Show a single frame from recorded episode.\"\"\"\n",
    "    if hasattr(data, 'combined_frames') and data.combined_frames:\n",
    "        frame_idx = min(step, len(data.combined_frames) - 1)\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.imshow(data.combined_frames[frame_idx])\n",
    "        plt.axis('off')\n",
    "        phase = data.infos[frame_idx].get('phase', 'unknown') if data.infos else 'unknown'\n",
    "        plt.title(f'{title} - Step {step} (Phase: {phase})', fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "# Show key moments from CMA-ES episode\n",
    "print(\"CMA-ES Controller:\")\n",
    "show_frame(cmaes_data, 50, \"CMA-ES: Pre-movement\")\n",
    "show_frame(cmaes_data, 150, \"CMA-ES: Mid-reach\")\n",
    "show_frame(cmaes_data, 250, \"CMA-ES: Near target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Full Checkpoint Inspection\n",
    "\n",
    "Generate comprehensive inspection plots for a trained controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization import inspect_checkpoint\n",
    "\n",
    "# Full inspection of CMA-ES controller\n",
    "print(\"=\"*60)\n",
    "print(\"CMA-ES Controller Inspection\")\n",
    "print(\"=\"*60)\n",
    "inspect_checkpoint(\n",
    "    checkpoint_path=CMAES_PATH,\n",
    "    xml_path=XML_PATH,\n",
    "    output_dir='outputs/cmaes/inspection',\n",
    "    num_episodes=3,\n",
    "    max_steps=300,\n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Training History Visualization\n",
    "\n",
    "Plot training curves to see convergence behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization import plot_training_curves\n",
    "import json\n",
    "\n",
    "# Plot CMA-ES training history\n",
    "cmaes_history_path = 'outputs/cmaes/history.json'\n",
    "if Path(cmaes_history_path).exists():\n",
    "    plot_training_curves(cmaes_history_path, show=True)\n",
    "else:\n",
    "    print(f\"Training history not found at {cmaes_history_path}\")\n",
    "    print(\"Run training first to generate history.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Summary and Conclusions\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Aspect | CMA-ES | Distillation |\n",
    "|--------|--------|--------------|\n",
    "| **Training** | Black-box, no gradients | Gradient-based, two-phase |\n",
    "| **Speed** | Slower (evolutionary) | Faster (supervised) |\n",
    "| **Parallelization** | Excellent (CPU) | Limited (GPU preferred) |\n",
    "| **Reflex Learning** | Learns from scratch | Learns from teacher |\n",
    "\n",
    "### Generated Outputs\n",
    "\n",
    "After running this notebook, you'll have:\n",
    "- `outputs/cmaes/` - CMA-ES training results, checkpoints, visualizations\n",
    "- `outputs/distillation/` - Distillation training results\n",
    "- Network activity videos showing real-time neural processing\n",
    "- Episode summary plots with phase-shaded regions\n",
    "- Reflex connection heatmaps\n",
    "\n",
    "### Command Line Usage\n",
    "\n",
    "For faster training with multiprocessing:\n",
    "\n",
    "```bash\n",
    "# CMA-ES training\n",
    "python run.py train mujoco/arm.xml --method cmaes \\\n",
    "    --generations 500 --population 64 --workers 8 \\\n",
    "    --inspection-every 25\n",
    "\n",
    "# Distillation training  \n",
    "python run.py train mujoco/arm.xml --method distillation \\\n",
    "    --teacher-epochs 100 --student-epochs 200\n",
    "\n",
    "# Visualization\n",
    "python run.py visualize mujoco/arm.xml outputs/cmaes/best_controller_final.pt\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
