{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753a2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from evojax.policy.base import PolicyNetwork\n",
    "\n",
    "\n",
    "class MinimalRNN(nn.Module):\n",
    "    input_dim: int\n",
    "    hidden_dim: int\n",
    "    output_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, h):\n",
    "        xh = jnp.concatenate([x, h])\n",
    "        h_new = nn.tanh(nn.Dense(self.hidden_dim)(xh))\n",
    "        out = nn.Dense(self.output_dim)(h_new)\n",
    "        return out, h_new\n",
    "\n",
    "\n",
    "class SimpleRNNPolicy(PolicyNetwork):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = MinimalRNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "        dummy_input = jnp.zeros((input_dim,))\n",
    "        dummy_hidden = jnp.zeros((hidden_dim,))\n",
    "        self._param_tree = self.model.init(jax.random.PRNGKey(0), dummy_input, dummy_hidden)\n",
    "        self._param_size = sum(x.size for x in jax.tree_util.tree_leaves(self._param_tree[\"params\"]))\n",
    "\n",
    "    def get_params(self):\n",
    "        return self._param_tree[\"params\"]\n",
    "\n",
    "    @property\n",
    "    def param_size(self):\n",
    "        return self._param_size\n",
    "\n",
    "    def forward(self, params, obs, hidden):\n",
    "        return self.model.apply({'params': params}, obs, hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e659864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mujoco\n",
    "import mujoco.mjx as mjx\n",
    "from evojax.task.base import VectorizedTask\n",
    "\n",
    "\n",
    "class MJXDummyTask(VectorizedTask):\n",
    "    def __init__(self, xml_path=\"mjcf/half_cheetah.xml\", episode_length=200):\n",
    "        self.model = mjx.put_model(mujoco.MjModel.from_xml_path(xml_path))\n",
    "        self.episode_length = episode_length\n",
    "\n",
    "        self.obs_size = self.model.nq + self.model.nv\n",
    "        self.act_size = self.model.nu\n",
    "\n",
    "    @property\n",
    "    def obs_shape(self):\n",
    "        return (self.obs_size,)\n",
    "\n",
    "    @property\n",
    "    def action_shape(self):\n",
    "        return (self.act_size,)\n",
    "\n",
    "    def reset(self, rng):\n",
    "        data = mjx.make_data(self.model)\n",
    "        obs = jnp.concatenate([data.qpos, data.qvel])\n",
    "        hidden = jnp.zeros((32,))  # match RNN hidden dim\n",
    "        return obs, hidden\n",
    "\n",
    "    def step(self, obs, action):\n",
    "        reward = -jnp.sum(action**2)\n",
    "        done = False\n",
    "        return obs, reward, done, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5634cdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ParseXML: Error opening file 'mjcf/half_cheetah.xml': No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     21\u001b[39m     trainer.train()\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     task = \u001b[43mMJXDummyTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     policy = SimpleRNNPolicy(input_dim=task.obs_shape[\u001b[32m0\u001b[39m], output_dim=task.act_shape[\u001b[32m0\u001b[39m])\n\u001b[32m      8\u001b[39m     algo = PGPE(\n\u001b[32m      9\u001b[39m         pop_size=\u001b[32m64\u001b[39m,\n\u001b[32m     10\u001b[39m         param_size=policy.param_size,\n\u001b[32m     11\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mMJXDummyTask.__init__\u001b[39m\u001b[34m(self, xml_path, episode_length)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xml_path=\u001b[33m\"\u001b[39m\u001b[33mmjcf/half_cheetah.xml\u001b[39m\u001b[33m\"\u001b[39m, episode_length=\u001b[32m200\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = mjx.put_model(\u001b[43mmujoco\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMjModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_xml_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mself\u001b[39m.episode_length = episode_length\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mself\u001b[39m.obs_size = \u001b[38;5;28mself\u001b[39m.model.nq + \u001b[38;5;28mself\u001b[39m.model.nv\n",
      "\u001b[31mValueError\u001b[39m: ParseXML: Error opening file 'mjcf/half_cheetah.xml': No such file or directory"
     ]
    }
   ],
   "source": [
    "from evojax import Trainer\n",
    "from evojax.algo import PGPE\n",
    "\n",
    "\n",
    "def main():\n",
    "    task = MJXDummyTask()\n",
    "    policy = SimpleRNNPolicy(input_dim=task.obs_shape[0], output_dim=task.act_shape[0])\n",
    "    algo = PGPE(\n",
    "        pop_size=64,\n",
    "        param_size=policy.param_size,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        task=task,\n",
    "        algo=algo,\n",
    "        policy=policy,\n",
    "        max_iterations=100,\n",
    "        test_interval=10,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
